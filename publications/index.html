<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Multimodal AI Lab </title> <meta name="author" content="Multimodal AI Lab "> <meta name="description" content="$^\star$ equal contribution"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/ewha_mark.png?fad73189fea69e68ef643de17b5cb995"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ewha-mil.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Multimodal AI Lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Members </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/faculty/">Faculty</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/students/">Students</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">$^\star$ equal contribution</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Video</abbr> </div> <div id="park2025byov" class="col-sm-8"> <div class="title">Bootstrap Your Own Views: Masked Ego-Exo Modeling for Fine-grained View-invariant Video Representations</div> <div class="author"> <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park</a>, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee<sup>*</sup></b>, and Kwanghoon Sohnf </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision Pattern Recognition (CVPR)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/park-jungin/byov" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://arxiv.org/abs/2503.19706" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">park2025byov</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Bootstrap Your Own Views: Masked Ego-Exo Modeling for Fine-grained View-invariant Video Representations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Park, Jungin and Lee, Jiyoung and Sohnf, Kwanghoon}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/CVF International Conference on Computer Vision Pattern Recognition (CVPR)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2503.19706}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal, Generation</abbr> </div> <div id="jeong2025read" class="col-sm-8"> <div class="title">Read, watch and scream! sound generation from text and video</div> <div class="author"> Yujin Jeong , Yunji Kim, Sanghyuk Chun, and <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> </div> <div class="periodical"> <em>In AAAI Conference on Artificial Intelligence (AAAI)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/naver-ai/rewas" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://naver-ai.github.io/rewas/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Project</a> <a href="https://arxiv.org/abs/2407.05551" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">jeong2025read</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Read, watch and scream! sound generation from text and video}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jeong, Yujin and Kim, Yunji and Chun, Sanghyuk and Lee, Jiyoung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI Conference on Artificial Intelligence (AAAI)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2407.05551}</span><span class="p">,</span>
  <span class="na">project</span> <span class="p">=</span> <span class="s">{https://naver-ai.github.io/rewas/}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="kim2024prototype" class="col-sm-8"> <div class="title">Prototype-Guided Attention Distillation for Discriminative Person Search</div> <div class="author"> Hanjae Kim, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , and Kwanghoon Sohn </div> <div class="periodical"> <em>IEEE transactions on pattern analysis and machine intelligence (TPAMI)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/abstract/document/10681282/?casa_token=WYcfmu0QvLsAAAAA:2LG14u7yf7IeilWhcmSri1GjOWxIbffWHwr-9LQUAd9JdkfIyhzqV2uhH26dfSuW54aMBG5cEw" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Video</abbr> </div> <div id="lee2024discriminative" class="col-sm-8"> <div class="title">Discriminative action tubelet detector for weakly-supervised action detection</div> <div class="author"> <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , Seungryong Kim , Sunok Kim , and Kwanghoon Sohn </div> <div class="periodical"> <em>Pattern Recognition</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://www.sciencedirect.com/science/article/pii/S0031320324004552?casa_token=-3WwtSDPclUAAAAA:luVmwjyqLhLSmq48_ycR70WEyPbwXDyhkPejuPGY_uC20bWT0Rl3ioT_6gN67OG-xXQWPfcvbQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal, Generation</abbr> </div> <div id="parkbridging" class="col-sm-8"> <div class="title">Bridging Vision and Language Spaces with Assignment Prediction</div> <div class="author"> <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park</a>, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee<sup>*</sup></b> , and Kwanghoon Sohn<sup>*</sup> </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://github.com/park-jungin/vlap" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://arxiv.org/abs/2404.09632" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal, 3D, Generation</abbr> </div> <div id="seolet" class="col-sm-8"> <div class="title">Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation</div> <div class="author"> Junyoung Seo, Wooseok Jang, Min-Seop Kwak , Hyeonsu Kim, Jaehoon Ko , Junho Kim , Jin-Hwa Kim<sup>*</sup>, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee<sup>*</sup></b> , and Seungryong Kim<sup>*</sup> </div> <div class="periodical"> <em>In International Conference on Learning Representations (ICLR)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://github.com/cvlab-kaist/3DFuse" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://cvlab-kaist.github.io/3DFuse/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Project</a> <a href="https://arxiv.org/abs/2303.07937" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, 3D, Generation</abbr> </div> <div id="heo2023robust" class="col-sm-8"> <div class="title">Robust camera pose refinement for multi-resolution hash encoding</div> <div class="author"> Hwan Heo , Taekyung Kim, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , Jaewon Lee , Soohyun Kim , Hyunwoo J Kim<sup>*</sup> , and Jin-Hwa Kim<sup>*</sup> </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://proceedings.mlr.press/v202/heo23a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Generation</abbr> </div> <div id="seo2023midms" class="col-sm-8"> <div class="title">Midms: Matching interleaved diffusion models for exemplar-based image translation</div> <div class="author"> Junyoung Seo , Gyuseong Lee, Seokju Cho, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , and Seungryong Kim </div> <div class="periodical"> <em>In AAAI Conference on Artificial Intelligence (AAAI)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://github.com/cvlab-kaist/MIDMs" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://cvlab-kaist.github.io/MIDMs/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Project</a> <a href="https://arxiv.org/abs/2209.11047" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal, Generation</abbr> </div> <div id="lee2023imaginary" class="col-sm-8"> <div class="title">Imaginary voice: Face-styled diffusion model for text-to-speech</div> <div class="author"> <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b>, Joon Son Chung, and Soo-Whan Chung </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://github.com/naver-ai/facetts" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://facetts.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Project</a> <a href="https://arxiv.org/abs/2302.13700" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Preprint, Generation</abbr> </div> <div id="kim2023panoramic" class="col-sm-8"> <div class="title">Panoramic Image-to-Image Translation</div> <div class="author"> Soohyun Kim , Junho Kim , Taekyung Kim, Hwan Heo , Seungryong Kim<sup>*</sup>, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee<sup>*</sup></b> , and Jin-Hwa Kim<sup>*</sup> </div> <div class="periodical"> <em>arXiv preprint arXiv:2304.04960</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2304.04960" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Preprint, Generation</abbr> </div> <div id="kim2023semi" class="col-sm-8"> <div class="title">Semi-parametric video-grounded text generation</div> <div class="author"> Sungdong Kim , Jin-Hwa Kim, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b>, and Minjoon Seo </div> <div class="periodical"> <em>arXiv preprint arXiv:2301.11507</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2301.11507" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal, Generation</abbr> </div> <div id="kim2023dense" class="col-sm-8"> <div class="title">Dense text-to-image generation with attention modulation</div> <div class="author"> Yunji Kim, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , Jin-Hwa Kim, Jung-Woo Ha, and Jun-Yan Zhu </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://github.com/naver-ai/DenseDiffusion" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://github.com/XandrChris/DenseDiffusionColab" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Demo</a> <a href="https://arxiv.org/abs/2308.12964" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal, CZSL</abbr> </div> <div id="kim2023hierarchical" class="col-sm-8"> <div class="title">Hierarchical visual primitive experts for compositional zero-shot learning</div> <div class="author"> Hanjae Kim, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , Seongheon Park , and Kwanghoon Sohn </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://github.com/HanjaeKim98/CoT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://arxiv.org/abs/2308.04016" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Generation</abbr> </div> <div id="moon2023three" class="col-sm-8"> <div class="title">Three recipes for better 3d pseudo-gts of 3d human mesh estimation in the wild</div> <div class="author"> Gyeongsik Moon, Hongsuk Choi, Sanghyuk Chun, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b>, and Sangdoo Yun </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision Pattern Recognition Workshops (CVPRW)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://github.com/mks0601/NeuralAnnot_RELEASE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Project</a> <a href="https://arxiv.org/abs/2304.04875" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Video</abbr> </div> <div id="park2023dual" class="col-sm-8"> <div class="title">Dual-path adaptation from image to video transformers</div> <div class="author"> <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park<sup>*</sup></a>, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee<sup>*</sup></b> , and Kwanghoon Sohn </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision Pattern Recognition (CVPR)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2303.09857" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Video</abbr> </div> <div id="kim2023language" class="col-sm-8"> <div class="title">Language-free training for zero-shot video grounding</div> <div class="author"> Dahye Kim, <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park</a>, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , Seongheon Park , and Kwanghoon Sohn </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2210.12977" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, 3D</abbr> </div> <div id="kim2022pointfix" class="col-sm-8"> <div class="title">Pointfix: Learning to fix domain bias for robust online stereo adaptation</div> <div class="author"> Kwonyoung Kim, <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park</a>, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b>, Dongbo Min , and Kwanghoon Sohn </div> <div class="periodical"> <em>In European Conference on Computer Vision (ECCV)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2207.13340" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="mcduff2022causalcity" class="col-sm-8"> <div class="title">Causalcity: Complex simulations with agency for causal discovery and reasoning</div> <div class="author"> Daniel McDuff, Yale Song, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b>, Vibhav Vineet, Sai Vemprala, Nicholas Alexander Gyde, Hadi Salman, Shuang Ma , Kwanghoon Sohn, and Ashish Kapoor </div> <div class="periodical"> <em>In Conference on Causal Learning and Reasoning</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://causalcity.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Project</a> <a href="https://arxiv.org/abs/2106.13364" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal, Generation</abbr> </div> <div id="kim2022mutual" class="col-sm-8"> <div class="title">Mutual information divergence: A unified metric for multimodal generative models</div> <div class="author"> Jin-Hwa Kim , Yunji Kim, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b>, Kang Min Yoo , and Sang-Woo Lee </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems (NeurIPS)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://github.com/naver-ai/mid.metric" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://arxiv.org/abs/2205.13445" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Generation</abbr> </div> <div id="jeong2022multi" class="col-sm-8"> <div class="title">Multi-domain unsupervised image-to-image translation with appearance adaptive convolution</div> <div class="author"> Somi Jeong, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , and Kwanghoon Sohn </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2202.02779" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <div>Vision</div> </abbr> </div> <div id="kim2022pin" class="col-sm-8"> <div class="title">Pin the memory: Learning to generalize semantic segmentation</div> <div class="author"> Jin Kim, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b>, <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park</a>, Dongbo Min , and Kwanghoon Sohn </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision Pattern Recognition (CVPR)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://github.com/Genie-Kim/PintheMemory" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://arxiv.org/abs/2204.03609" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Video</abbr> </div> <div id="park2022probabilistic" class="col-sm-8"> <div class="title">Probabilistic representations for video contrastive learning</div> <div class="author"> <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park</a>, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , Ig-Jae Kim , and Kwanghoon Sohn </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision Pattern Recognition (CVPR)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2204.03946" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Video</abbr> </div> <div id="cho2021wide" class="col-sm-8"> <div class="title">Wide and Narrow: Video Prediction from Context and Motion</div> <div class="author"> Jaehoon Cho, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b>, Changjae Oh, Wonil Song , and Kwanghoon Sohn </div> <div class="periodical"> <em>In British Machine Vision Conference (BMVC)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2110.11586" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <div>Vision</div> </abbr> </div> <div id="kim2021self" class="col-sm-8"> <div class="title">Self-balanced learning for domain generalization</div> <div class="author"> Jin Kim, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b>, <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park</a>, Dongbo Min , and Kwanghoon Sohn </div> <div class="periodical"> <em>In IEEE international conference on image processing (ICIP)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2108.13597" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal, Video</abbr> </div> <div id="park2021bridge" class="col-sm-8"> <div class="title">Bridge to answer: Structure-aware graph interaction network for video question answering</div> <div class="author"> <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park</a>, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , and Kwanghoon Sohn </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision Pattern Recognition (CVPR)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2104.14085" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal, AVSS</abbr> </div> <div id="lee2021looking" class="col-sm-8"> <div class="title">Looking into your speech: Learning cross-modal affinity for audio-visual speech separation</div> <div class="author"> <b style="color: #{$green-color-dark} !important;">Jiyoung Lee<sup>*</sup></b>, Soo-Whan Chung<sup>*</sup> , Sunok Kim, Hong-Goo Kang<sup>*</sup> , and Kwanghoon Sohn<sup>*</sup> </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision Pattern Recognition (CVPR)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2104.02775" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal, Affective Computing</abbr> </div> <div id="lee2020multi" class="col-sm-8"> <div class="title">Multi-modal recurrent attention networks for facial expression recognition</div> <div class="author"> <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , Sunok Kim , Seungryong Kim , and Kwanghoon Sohn </div> <div class="periodical"> <em>IEEE Transactions on Image Processing</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/abstract/document/9102419" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Video</abbr> </div> <div id="park2020sumgraph" class="col-sm-8"> <div class="title">Sumgraph: Video summarization via recursive graph modeling</div> <div class="author"> <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park<sup>*</sup></a>, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee<sup>*</sup></b> , Ig-Jae Kim , and Kwanghoon Sohn </div> <div class="periodical"> <em>In European Conference on Computer Vision (ECCV)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2007.08809" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Video</abbr> </div> <div id="park2019graph" class="col-sm-8"> <div class="title">Graph regularization network with semantic affinity for weakly-supervised temporal action localization</div> <div class="author"> <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park</a>, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b>, Sangryul Jeon , Seungryong Kim , and Kwanghoon Sohn </div> <div class="periodical"> <em>In IEEE International conference on image processing (ICIP)</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/document/8803589" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <div>Vision</div> </abbr> </div> <div id="park2019video" class="col-sm-8"> <div class="title">Video summarization by learning relationships between action and scene</div> <div class="author"> <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park</a>, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b>, Sangryul Jeon , and Kwanghoon Sohn </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">3rd place</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/CoView/Park_Video_Summarization_by_Learning_Relationships_between_Action_and_Scene_ICCVW_2019_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="award hidden d-print-inline"> <p></p> <p><em>3rd place</em> in the <strong>ICCV Challenge on Comprehensive Video Understanding in the Wild (CoVieW 2019)</strong></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">park2019video</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Video summarization by learning relationships between action and scene}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Park, Jungin and Lee, Jiyoung and Jeon, Sangryul and Sohn, Kwanghoon}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://openaccess.thecvf.com/content_ICCVW_2019/papers/CoView/Park_Video_Summarization_by_Learning_Relationships_between_Action_and_Scene_ICCVW_2019_paper.pdf}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Affective Computing</abbr> </div> <div id="lee2019context" class="col-sm-8"> <div class="title">Context-aware emotion recognition networks</div> <div class="author"> <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , Seungryong Kim , Sunok Kim, <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park</a> , and Kwanghoon Sohn<sup>*</sup> </div> <div class="periodical"> <em>In IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://caer-dataset.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Project</a> <a href="https://arxiv.org/abs/1908.05913" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lee2019context</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Context-aware emotion recognition networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lee, Jiyoung and Kim, Seungryong and Kim, Sunok and Park, Jungin and Sohn, Kwanghoon}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/CVF International Conference on Computer Vision (ICCV)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/1908.05913}</span><span class="p">,</span>
  <span class="na">project</span> <span class="p">=</span> <span class="s">{https://caer-dataset.github.io/}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Multimodal, Affective Computing</abbr> </div> <div id="lee2018audio" class="col-sm-8"> <div class="title">Audio-visual attention networks for emotion recognition</div> <div class="author"> <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , Sunok Kim , Seungryong Kim , and Kwanghoon Sohn </div> <div class="periodical"> <em>In Proceedings of the 2018 Workshop on Audio-Visual Scene Understanding for Immersive Multimedia</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Video</abbr> </div> <div id="park2018learning" class="col-sm-8"> <div class="title">Learning to detect, associate, and recognize human actions and surrounding scenes in untrimmed videos</div> <div class="author"> <a href="https://park-jungin.github.io/" rel="external nofollow noopener" target="_blank">Jungin Park</a>, Sangryul Jeon , Seungryong Kim, <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , Sunok Kim , and Kwanghoon Sohn </div> <div class="periodical"> <em>In Proceedings of the 1st Workshop and Challenge on Comprehensive Video Understanding in the Wild</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, Affective Computing</abbr> </div> <div id="lee2018spatiotemporal" class="col-sm-8"> <div class="title">Spatiotemporal attention based deep neural networks for emotion recognition</div> <div class="author"> <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b> , Sunok Kim, Seungryong Kiim , and Kwanghoon Sohn </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="https://ieeexplore.ieee.org/document/8461920" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Vision, 3D</abbr> </div> <div id="lee2017automatic" class="col-sm-8"> <div class="title">Automatic 2d-to-3d conversion using multi-scale deep neural network</div> <div class="author"> <b style="color: #{$green-color-dark} !important;">Jiyoung Lee</b>, Hyungjoo Jung , Youngjung Kim , and Kwanghoon Sohn </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing (ICIP)</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Multimodal AI Lab . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>